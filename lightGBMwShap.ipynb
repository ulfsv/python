{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from  sklearn.model_selection import train_test_split\n",
    "from ml_metrics import rmsle as metric\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "def rmsle(true, labels):\n",
    "    pred = labels.get_label()\n",
    "    if len(pred)==len(true):\n",
    "        pred[pred<0] = 0\n",
    "        rmsle = np.sqrt((sum((np.log(pred+1) - np.log(true+1))**2))/len(true))\n",
    "        return 'rmsle', rmsle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full table:   6.1Gb\n",
    "# This version: 1.1Gb (-82%)\n",
    "start_time = time.time()\n",
    "types = {'Semana':np.uint8,'Agencia_ID':np.uint16, 'Canal_ID':np.uint8,\n",
    "         'Ruta_SAK':np.uint16, 'Cliente_ID':np.uint32, 'Producto_ID':np.uint16,\n",
    "         'Demanda_uni_equil':np.uint32}\n",
    "\n",
    "train = pd.read_csv('../../data/kaggle/train.csv', usecols=types.keys(), dtype=types)\n",
    "#,nrows = 7000000\n",
    "print(\"Elapsed time overall: %s seconds\" % (time.time() - start_time))\n",
    "print(train.info(memory_usage=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the shape of the loaded data set\n",
    "With train.shape we can see information about number of rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Training_Shape:', train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print 2 rows of the train data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train data set \n",
    "We split the train data set in a train data set (59344371 rows) and a test data set (14836093 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data and use the columns\n",
    "test = pd.read_csv('../../data/kaggle/test.csv')\n",
    "test.head(2)\n",
    "ids = test['id']\n",
    "test = test.drop(['id'],axis = 1)\n",
    "y1 = train['Demanda_uni_equil']\n",
    "y = np.log(train['Demanda_uni_equil'] + 1)\n",
    "\n",
    "X = train[test.columns.values]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2019)\n",
    "\n",
    "print ('Division_Set_Shapes:', X.shape, y.shape)\n",
    "print ('Validation_Set_Shapes:', X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['objective'] = \"reg:linear\"\n",
    "booster = \"gbtree\"\n",
    "# params['eta'] = 0.025\n",
    "#params['eta'] = 0.015\n",
    "#params['eta'] = 0.04\n",
    "params['eta'] = 0.03\n",
    "params['max_depth'] = 10\n",
    "#params['subsample'] = 0.8\n",
    "params['subsample'] = 0.9\n",
    "#params['colsample_bytree'] = 0.6\n",
    "params['colsample_bytree'] = 0.7\n",
    "params['silent'] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Constructing matrix')\n",
    "\n",
    "#xg_train = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "#xg_test = xgb.DMatrix(X_test)\n",
    "\n",
    "train_data=lgb.Dataset(X_train, label=y_train)\n",
    "valid_data=lgb.Dataset(X_test,label=y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'binary_logloss'},\n",
    "    'num_leaves': 96,\n",
    "    'max_depth': 10,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.95,\n",
    "    'bagging_freq': 5\n",
    "}\n",
    "ROUNDS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Select Hyper-Parameters\n",
    "params = {'metric' : 'rmse',\n",
    "          'boosting_type' : 'gbdt',\n",
    "          #'xgboost_dart_mode' : 'true',\n",
    "          'colsample_bytree' : 0.9234,\n",
    "          #'colsample_bytree' : 0.7,\n",
    "          'num_leaves' : 13,\n",
    "          'max_depth' : -1,\n",
    "          'n_estimators' : 200,\n",
    "          'min_child_samples': 399, \n",
    "          'min_child_weight': 0.1,\n",
    "          'reg_alpha': 2,\n",
    "          'reg_lambda': 5,\n",
    "          'subsample': 0.855,\n",
    "          'verbose' : -1,\n",
    "          'num_threads' : 4\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"objective\" : \"regression\", \"metric\" : \"rmse\", 'n_estimators':10000, 'early_stopping_rounds':100,\n",
    "              \"num_leaves\" : 30, \"learning_rate\" : 0.01, \"bagging_fraction\" : 0.9,\n",
    "              \"feature_fraction\" : 0.3, \"bagging_seed\" : 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model on selected parameters and number of iterations\n",
    "start_time = time.time()\n",
    "lgbm = lgb.train(params,\n",
    "                 train_data,\n",
    "                 2500,\n",
    "                 valid_sets=valid_data,\n",
    "                 early_stopping_rounds= 30,\n",
    "                 verbose_eval= 10\n",
    "                 )\n",
    "#print('rmsle:', metric(y_test, pred))\n",
    "print(\"Elapsed time overall: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = lgbm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the model to disk\n",
    "filename = 'lgbmlassifier15nov-2.sav'\n",
    "pickle.dump(lgbm, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import saved model\n",
    "import pickle\n",
    "filename = 'lgbmlassifier15nov-2.sav'\n",
    "# load the model from disk\n",
    "lgbm = pickle.load(open(filename, 'rb'))\n",
    "result = lgbm\n",
    "print(lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap_values = shap.TreeExplainer(lgbm).shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"Producto_ID\", shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"Canal_ID\", shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"Ruta_SAK\", shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = shap.TreeExplainer(lgbm).shap_values(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explain the model's predictions using SHAP values\n",
    "# (same syntax works for LightGBM, CatBoost, and scikit-learn models)\n",
    "# load JS visualization code to notebook\n",
    "import shap\n",
    "\n",
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(lgbm)\n",
    "shap_values = explainer.shap_values(X)\n",
    "\n",
    "# visualize the first prediction's explanation\n",
    "shap.force_plot(explainer.expected_value, shap_values[0,:], X.iloc[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic classifier from xgboost\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "xgclassifier = xgb.train(params, xg_train, num_rounds, watchlist, feval = rmsle, early_stopping_rounds= 10, verbose_eval = True)\n",
    "preds = xgclassifier.predict(xg_test, ntree_limit=xgclassifier.best_iteration)\n",
    "    \n",
    "#print ('RMSLE Score:', rmsle(y_test, preds))\n",
    "print('rmsle:', metric(y_test, preds))\n",
    "print(\"Elapsed time overall: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the model to disk\n",
    "filename = 'xgclassifier14nov.sav'\n",
    "pickle.dump(xgclassifier, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import saved model\n",
    "import pickle\n",
    "filename = 'xgclassifier14nov.sav'\n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predsny = loaded_model.predict(xg_test, ntree_limit=29)\n",
    "print(predsny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic classifier from xgboost\n",
    "# train with all training data\n",
    "\n",
    "start_time = time.time()\n",
    "test_preds = np.zeros(test.shape[0])\n",
    "trainData = xgb.DMatrix(X, label=y)\n",
    "watchlist = [(trainData, 'train')]\n",
    "\n",
    "num_rounds = 2\n",
    "\n",
    "xgclassifier = xgb.train(params, trainData, num_rounds, watchlist, feval = evalerror, early_stopping_rounds= 10, verbose_eval = True)\n",
    "preds = xgclassifier.predict(xg_test, ntree_limit=xgclassifier.best_iteration)\n",
    "    \n",
    "print ('RMSLE Score:', rmsle(y_test, preds))\n",
    "\n",
    "print(\"Elapsed time overall: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the saved model\n",
    "start_time2 = time.time()\n",
    "test = pd.read_csv('../../data/kaggle/test.csv')\n",
    "test_id = test['id']\n",
    "test = test.drop(['id'],axis = 1)\n",
    "test_preds = np.zeros(test.shape[0])\n",
    "unlabeled_test = xgb.DMatrix(test)\n",
    "fold_preds = np.around(loaded_model.predict(unlabeled_test, ntree_limit=39), decimals = 0)\n",
    "test_preds += fold_preds\n",
    "res=np.exp(test_preds)-1\n",
    "\n",
    "print(\"Elapsed time overall: %s seconds\" % (time.time() - start_time2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id':id, 'Demanda_uni_equil': res})\n",
    "submission.to_csv('submission-loadedmodel14nov.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as offline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "offline.init_notebook_mode()\n",
    "#res=np.exp(test_preds)-1\n",
    "res2=np.exp(y_test)-1\n",
    "#x = test_id[14835500:14836093]\n",
    "#y = res[14835500:14836093]\n",
    "#2 = test_id[14835500:14836093]\n",
    "#y2 = y_test[14835500:14836093]\n",
    "\n",
    "predicted = go.Scatter(\n",
    "    x=test_id[6998251:6999251],\n",
    "    y=res[6998251:6999251]\n",
    ")\n",
    "actual = go.Scatter(\n",
    "    x=test_id[6998251:6999251],\n",
    "    y= res2[6998251:6999251]\n",
    ")\n",
    "\n",
    "data = [predicted, actual]\n",
    "offline.iplot(data, filename='bar-line')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fxg_test = xgb.DMatrix(test)\n",
    "fold_preds = np.around(xgclassifier.predict(fxg_test, ntree_limit=xgclassifier.best_iteration), decimals = 1)\n",
    "test_preds += fold_preds\n",
    "\n",
    "submission = pd.DataFrame({'id':ids, 'Demanda_uni_equil': test_preds})\n",
    "submission.to_csv('submission-2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../../data/kaggle/test.csv')\n",
    "test_id = test['id']\n",
    "test = test.drop(['id'],axis = 1)\n",
    "test_preds = np.zeros(test.shape[0])\n",
    "unlabeled_test = xgb.DMatrix(test)\n",
    "fold_preds = np.around(xgclassifier.predict(unlabeled_test, ntree_limit=xgclassifier.best_iteration), decimals = 1)\n",
    "test_preds += fold_preds\n",
    "\n",
    "submission = pd.DataFrame({'id':test_id, 'Demanda_uni_equil': test_preds})\n",
    "submission.to_csv('submissionTest2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from ml_metrics import rmsle as metric\n",
    "from sklearn import preprocessing as ppr\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "def rmsle(true, labels):\n",
    "    pred = labels.get_label()\n",
    "    if len(pred)==len(true):\n",
    "        pred[pred<0] = 0\n",
    "        rmsle = np.sqrt((sum((np.log(pred+1) - np.log(true+1))**2))/len(true))\n",
    "        return 'rmsle', rmsle\n",
    "        \n",
    "train = pd.read_csv('../../data/kaggle/train.csv', nrows = 500000)\n",
    "test = pd.read_csv('../../data/kaggle/test.csv')\n",
    "\n",
    "test_id = test['id']\n",
    "test = test.drop(['id'],axis = 1)\n",
    "y = train['Demanda_uni_equil']\n",
    "X = train[test.columns.values]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4518)\n",
    "\n",
    "params = {'objective': \"reg:linear\",\n",
    "          'eta'      : 0.03,\n",
    "          'max_depth': 8}\n",
    "rounds = 200\n",
    "\n",
    "xgb_train = xgb.DMatrix(X_train, label=y_train)\n",
    "xgb_test = xgb.DMatrix(X_test)\n",
    "\n",
    "watchlist = [(xgb_train, 'train')]\n",
    "\n",
    "xgb_reg = xgb.train(params, xgb_train, rounds, watchlist, feval = rmsle, early_stopping_rounds= 20, verbose_eval = 10)\n",
    "preds = xgb_reg.predict(xgb_test, ntree_limit=xgb_reg.best_iteration)\n",
    "\n",
    "print('rmsle:', metric(y_test, preds))\n",
    "\n",
    "test_preds = np.zeros(test.shape[0])\n",
    "unlabeled_test = xgb.DMatrix(test)\n",
    "fold_preds = np.around(xgb_reg.predict(unlabeled_test, ntree_limit=xgb_reg.best_iteration), decimals = 1)\n",
    "test_preds += fold_preds\n",
    "\n",
    "submission = pd.DataFrame({'id':test_id, 'Demanda_uni_equil': test_preds})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
